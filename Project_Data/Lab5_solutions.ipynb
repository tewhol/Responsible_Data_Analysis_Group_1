{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b56f31da-b753-4d57-9d5c-aa869382e81f",
   "metadata": {},
   "source": [
    "# SEN163A - Responsible Data Analytics\n",
    "## Lab session 5: Predictive Analytics: Regression and Classification\n",
    "### Delft University of Technology\n",
    "### Q3 2023-24\n",
    "\n",
    "**Instructor**: Dr. Ir. Sepinoud Azimi Rashti - s.azimirashti@tudelft.nl\n",
    "\n",
    "**TAs**: Anagha Magadi Rajeev - a.magadirajeev@student.tudelft.nl\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "Lab session aim to:\n",
    "- Show and reinforce how models and ideas presented in class are put to practice.\n",
    "- Help you gather hands-on machine learning skills.\n",
    "\n",
    "Lab sessions are:\n",
    "\n",
    "- Learning environments where you work with Jupyter notebooks and where you can get support from TAs and fellow students.\n",
    "- Not graded and do not have to be submitted.\n",
    "- A good preparation for the assignments (which are graded).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f654ba8d-7ccf-4014-9364-b974dd0c3f1f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Application: Predictive analytics of a health and insurance related data\n",
    "\n",
    "In this lab session, we will explore how to performe predicitive analytics to solve both a classification (predicting a categorical variable) and a regression (predicting a numerical variable) task. \n",
    "The classification case will be related to the prediction of the occurrence of a stroke, based on both physiological measurements as well as user features.\n",
    "The regression case, on the other hand, will be related to the prediction of health insurance costs, based on user features and behaviour.\n",
    "\n",
    "#### Learning objectives\n",
    "After completing the following exercises you will be able to:\n",
    "\n",
    "1. Apply common preprocessing techniques to prepare data for machine learning techniques: categorical preprocessing, imputation.\n",
    "2. Split the available dataset into a training set (for model fitting) and a testing set (for performance evaluation).\n",
    "3. Fit benchmark models to determine baseline performances on both a classification and regression case.\n",
    "4. Compute the most commonly applied performance measures for classification and regression tasks.\n",
    "5. Fit the most commonly applied machine learning predictive models for classification and regression tasks.\n",
    "6. Compare predictive models across different performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "243c302e-4aca-4a14-b28c-059dff58840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "\n",
    "import seaborn\n",
    "import matplotlib\n",
    "\n",
    "seaborn.set_palette(\"Set2\")\n",
    "seaborn.color_palette(\"Set2\")\n",
    "\n",
    "#\n",
    "seaborn.set(rc={\"figure.figsize\":(15, 10),\n",
    "            'legend.title_fontsize' : 25,\n",
    "            'legend.fontsize' : 20,\n",
    "            'xtick.labelsize' : 20,\n",
    "            'ytick.labelsize' : 20,\n",
    "            'axes.labelsize' : 25})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f36b96cf-152f-4fe7-87f3-b379053bfc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.set_context('notebook')\n",
    "#sns.set_context('paper')\n",
    "#sns.set_context('talk')\n",
    "#sns.set_context('poster')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cdd8da-d449-4299-a49a-66ad798c52dd",
   "metadata": {},
   "source": [
    "# Predictive Analytics - Classification example\n",
    "\n",
    "The classification task we will be tackling is based on the [Stroke Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset?select=healthcare-dataset-stroke-data.csv).\n",
    "\n",
    "In this case, we will use the available data to try to predict the occurrence of a stroke (`stroke` variable) as a function of the other variables.\n",
    "\n",
    "Before starting the modeling task, please have a look at the metadata about the [Stroke Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset?select=healthcare-dataset-stroke-data.csv), in order to better understand the meaning of the different variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc75f4f7-3397-406b-b1c3-1bed24c022b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "## Activity 1.1 - Descriptive analytics\n",
    "\n",
    "We are going to use the `pandas` library to perform some exploratory understanding of the data.\n",
    "\n",
    "1. Load the dataset `healthcare-dataset-stroke-data.csv` in the `stroke_df` variable\n",
    "2. Display the content of the `stroke_df` variable\n",
    "3. What are the type of the different columns? Use the knowledge from `pandas` to determine the type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b25dd37b-f5f1-499a-891a-6d293776dd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_df = pandas.read_csv(\"healthcare-dataset-stroke-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f16d305-55fe-4d8a-b1de-2672d655ef5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "0   9046    Male  67.0             0              1          Yes   \n",
       "1  51676  Female  61.0             0              0          Yes   \n",
       "2  31112    Male  80.0             0              1          Yes   \n",
       "3  60182  Female  49.0             0              0          Yes   \n",
       "4   1665  Female  79.0             1              0          Yes   \n",
       "\n",
       "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "0        Private          Urban             228.69  36.6  formerly smoked   \n",
       "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
       "2        Private          Rural             105.92  32.5     never smoked   \n",
       "3        Private          Urban             171.23  34.4           smokes   \n",
       "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
       "\n",
       "   stroke  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroke_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccbb2366-fe4c-4a10-b49c-11843e1c2ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5110 entries, 0 to 5109\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 5110 non-null   int64  \n",
      " 1   gender             5110 non-null   object \n",
      " 2   age                5110 non-null   float64\n",
      " 3   hypertension       5110 non-null   int64  \n",
      " 4   heart_disease      5110 non-null   int64  \n",
      " 5   ever_married       5110 non-null   object \n",
      " 6   work_type          5110 non-null   object \n",
      " 7   Residence_type     5110 non-null   object \n",
      " 8   avg_glucose_level  5110 non-null   float64\n",
      " 9   bmi                4909 non-null   float64\n",
      " 10  smoking_status     5110 non-null   object \n",
      " 11  stroke             5110 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 479.2+ KB\n"
     ]
    }
   ],
   "source": [
    "stroke_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e020c06-ce16-4e3c-98cd-dd0e452a00e0",
   "metadata": {},
   "source": [
    "## Activity 1.2 - Diagnostic analytics\n",
    "\n",
    "A common problem in many datasets is missing data, usually indicated by N/A, NA, NaN, and extreme values (outliers).\n",
    "\n",
    "As a reminder, several ways exist to deal with incomplete or missing data, the most common being:\n",
    "\n",
    "![MissingData](figures/MissingData.png)\n",
    "\n",
    "**Source:** *Skarga-Bandurova, I., Biloborodova, T., & Dyachenko, Y. (2018). Strategy to managing mixed datasets with missing items. In Information Processing and Management of Uncertainty in Knowledge-Based Systems. Theory and Foundations: 17th International Conference, IPMU 2018, Cádiz, Spain, June 11-15, 2018, Proceedings, Part II 17 (pp. 608-620). Springer International Publishing.*\n",
    "\n",
    "\n",
    "1. Is there any column containing missing data in this dataset?\n",
    "2. If there are any, display the column(s) containing missing data.\n",
    "3. Count the number of missing values in the column(s) containing missing data.\n",
    "4. Analyze the missing values and their potential causes, and propose the most appropriate way to process them in order to have a dataset without missing values for the further steps.\n",
    "5. Produce a new dataset `stroke_noNA_df` containing no missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43b805b6-eb3d-48da-9abd-58a0625654e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   False\n",
       "gender               False\n",
       "age                  False\n",
       "hypertension         False\n",
       "heart_disease        False\n",
       "ever_married         False\n",
       "work_type            False\n",
       "Residence_type       False\n",
       "avg_glucose_level    False\n",
       "bmi                   True\n",
       "smoking_status       False\n",
       "stroke               False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroke_df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ff668a7-a02a-4fc2-b3b2-a80ea90b24e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bmi'], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroke_df.columns[stroke_df.isna().any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b5ded9-0c07-4583-b536-0597707e9aa8",
   "metadata": {},
   "source": [
    "The only column including missing data is the BMI column, let's inspect it some more to see the nature of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c1b0c60-5bf5-4e56-94a6-38c3f5c24e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>30.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>26.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5110 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bmi\n",
       "0     36.6\n",
       "1      NaN\n",
       "2     32.5\n",
       "3     34.4\n",
       "4     24.0\n",
       "...    ...\n",
       "5105   NaN\n",
       "5106  40.0\n",
       "5107  30.6\n",
       "5108  25.6\n",
       "5109  26.2\n",
       "\n",
       "[5110 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroke_df[stroke_df.columns[stroke_df.isna().any()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "500dac9a-6b89-4090-9608-2f5a9ba96c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bmi    201\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(stroke_df[stroke_df.columns[stroke_df.isna().any()]].isna().sum())      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd20a494-daff-41a2-a273-3fb6b9192d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5110, 12)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroke_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc80d39-fce1-408b-9996-dd4f48b292da",
   "metadata": {},
   "source": [
    "The missing values are constituted by NaN values, and there is no available information to recompute the BMI from the other variables, so we are left with no choice but removing the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3406323f-7b02-47b0-a4e3-e86551e86ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_noNA_df = stroke_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43c47445-f451-4b12-8efa-307918d1d7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4909, 12)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroke_noNA_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc70b44-1cfa-40bd-a3d4-0d79c8488eb1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Activity 1.3\n",
    "\n",
    "In order to apply a Machine Learning predictive model on the [Stroke Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset?select=healthcare-dataset-stroke-data.csv) that we had previously imported in the `stroke_df` variable, we need to perform the following operations:\n",
    "\n",
    "1. Impute missing values (Done in 1.2 by dropping/imputing the missing values)\n",
    "2. Split data into training and test using the `train_test_split` function (1.3)\n",
    "3. Transform categorical variables (1.4)\n",
    "\n",
    "**N.B.**: Please note that the transformation in categorical variables needs to be done after the split into training and test set in order to avoid information leakage (normally the testing set should not be seen by the model during its training phase).\n",
    "\n",
    "We are going to use the `scikit-learn` library to perform most of the split and transformation tasks.\n",
    "\n",
    "Here you need to:\n",
    "1. Divide the `stroke_noNA_df` dataset into two variables:\n",
    "- `X` containing the input variables\n",
    "- `Y` containing the target variable (`stroke`)\n",
    "2. Use the `train_test_split` function to obtain `X_train, X_test, Y_train, Y_test` with a 70% train - 30% test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e77e691-eac9-4735-befe-70e08e97b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = stroke_noNA_df.iloc[:,1:11]\n",
    "Y = stroke_noNA_df.iloc[:,11]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beff7d4-61ad-41b5-8e9e-63553f810700",
   "metadata": {},
   "source": [
    "## Activity 1.4\n",
    "\n",
    "Before inputting the data to a Machine Learning model, we need all the inputs to be numeric.\n",
    "In order to transform categorical data into numeric ones, three techniques exist (cf. https://www.kaggle.com/code/alexisbcook/categorical-variables):\n",
    "- Dropping Categorical variables\n",
    "- Ordinal Encoding: A categorical variable is replaced by a single numerical variable, where each category is mapped to a different, increasing integer value.\n",
    "- One-hot Encoding: A categorical variable with $n$ different categories is replaced by $n$ binary variables, each of them corresponding to a category. \n",
    "\n",
    "We are going to use the `scikit-learn` library to perform the transformation of the variables and to subsequently fit the models.\n",
    "\n",
    "1. Have a look at the documentation of the [Scikit-learn](https://scikit-learn.org/stable/index.html) library \n",
    "2. Have a look at the following code to perform the transformation of categorical variables:\n",
    "- Dropping Categorical variables: `drop_X_train` and `drop_X_test`\n",
    "- Ordinal Encoding: `label_X_train` and `label_X_test`\n",
    "- One-hot Encoding: `OH_X_train` and `OH_X_test`\n",
    "\n",
    "TO DO: Add example with Pandas.get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05fcd7bb-28f2-48e5-b44d-be2922d37376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical variables:\n",
      "['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n"
     ]
    }
   ],
   "source": [
    "# Get list of categorical variables\n",
    "s = (X_train.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "print(\"Categorical variables:\")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f76689-e788-421d-a4f9-0dfa2aeb7902",
   "metadata": {},
   "source": [
    "### Dropping categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e106c3e-941f-4484-8c8a-4c08b08119b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_test = X_test.select_dtypes(exclude=['object'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82d6d73-093c-42d7-a78c-c3a68bad704d",
   "metadata": {},
   "source": [
    "### Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69e8df99-24f9-4ecd-b1c5-b362be368d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Make copy to avoid changing original data \n",
    "label_X_train = X_train.copy()\n",
    "label_X_test = X_test.copy()\n",
    "\n",
    "# Apply ordinal encoder to each column with categorical data\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "label_X_train[object_cols] = ordinal_encoder.fit_transform(X_train[object_cols])\n",
    "label_X_test[object_cols] = ordinal_encoder.transform(X_test[object_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7466b24-63a9-4cc8-a849-b724fd190521",
   "metadata": {},
   "source": [
    "### One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33b776ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.1.post1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca1bbdf8-a295-4796-a581-ce53d3494f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_train = pandas.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\n",
    "OH_cols_test = pandas.DataFrame(OH_encoder.transform(X_test[object_cols]))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_test = X_test.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pandas.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_test = pandas.concat([num_X_test, OH_cols_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1d292a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_X_train.info()\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_test.columns = OH_X_test.columns.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfa6f39-bce8-4506-a99a-3e27f419a055",
   "metadata": {},
   "source": [
    "## Activity 1.5\n",
    "\n",
    "Finally, with the data cleaned of missing values, and with the categorical variable appropriately transformed we are able to fit some models using the `scikit-learn` library.\n",
    "\n",
    "As seen in Lecture 5 a starter, we will will be using a baseline for classification models: a [Naive Bayesian Model](https://scikit-learn.org/stable/modules/naive_bayes.html)\n",
    "\n",
    "1. Have a look at the documentation of the [Scikit-learn](https://scikit-learn.org/stable/index.html) library for the Naive Bayes model.\n",
    "2. Initialize the model\n",
    "3. Use the `fit` function to perform the training of the model on the training set\n",
    "4. Use the `predict` function to perform the prediction of the model on the test set\n",
    "5. Use the `accuracy_score, balanced_accuracy_score, f1_score` to compare the predictions with the actual values and obtain different performance metrics about the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "deb50457-f2d1-4bfc-bfd0-ba026e0ab4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Dropped categorical):  0.8811948404616429\n",
      "F1 (Dropped categorical):  0.2616033755274262\n",
      "Accuracy (Ordinal encoding):  0.8689748811948405\n",
      "F1 (Ordinal encoding):  0.24313725490196078\n",
      "Accuracy (One-hot encoding):  0.41683638832315\n",
      "F1 (One-hot encoding):  0.13668341708542714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(drop_X_train, Y_train)\n",
    "Y_pred = gnb.predict(drop_X_test)\n",
    "print(\"Accuracy (Dropped categorical): \", accuracy_score(Y_test, Y_pred))\n",
    "print(\"F1 (Dropped categorical): \", f1_score(Y_test, Y_pred))\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(label_X_train, Y_train)\n",
    "Y_pred = gnb.predict(label_X_test)\n",
    "print(\"Accuracy (Ordinal encoding): \", accuracy_score(Y_test, Y_pred))\n",
    "print(\"F1 (Ordinal encoding): \", f1_score(Y_test, Y_pred))\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(OH_X_train, Y_train)\n",
    "Y_pred = gnb.predict(OH_X_test)\n",
    "print(\"Accuracy (One-hot encoding): \", accuracy_score(Y_test, Y_pred))\n",
    "print(\"F1 (One-hot encoding): \", f1_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e64a8a-f692-4646-b78b-0ad0d1aa223c",
   "metadata": {},
   "source": [
    "## Activity 1.6\n",
    "\n",
    "Now that you are familiar with the pipeline of training, testing and evaluating one model, you can easily repeat the procedure for multiple models.\n",
    "\n",
    "1. Have a look at the documentation of the [Scikit-learn](https://scikit-learn.org/stable/index.html) library for other classification models:\n",
    "    - Logistic Regression\n",
    "    - Decision Trees\n",
    "    - SVM\n",
    "    - Random Forest\n",
    "    - Gradient Boosting\n",
    "    - Artificial Neural Networks\n",
    "    - K-Nearest Neighbors\n",
    "2. For each model:\n",
    "    1. Initialize the model\n",
    "    2. Use the `fit` function to perform the training of the model on the training set\n",
    "    3. Use the `predict` function to perform the prediction of the model on the test set\n",
    "    4. Use the `accuracy_score, balanced_accuracy_score, f1_score` to compare the predictions with the actual values and obtain performance metrics about the models.\n",
    "    \n",
    "3. Create a dictionary/Data Frame in order to be able to compare the performance scores of the different models.\n",
    "    1. Are there any differences in the values of the metrics?\n",
    "    2. Why are these values different? Check the documentation to get to know more about the metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a2f9b381-3e48-4d3b-aa08-96ae02e21612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "names = [\n",
    "    \"Logistic Regression\",\n",
    "    \"Decision Tree\",\n",
    "    \"Linear SVM\",\n",
    "    \"Random Forest\",\n",
    "    \"AdaBoost\",\n",
    "    \"Neural Net\",\n",
    "    \"K-Nearest Neighbours\"\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(random_state=0),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    AdaBoostClassifier(),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    KNeighborsClassifier(3),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "29e349b1-e7fd-454d-959f-fc4979944de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] - Categorical technique:  Drop Variables\n",
      "[INFO] - Classifier:  Logistic Regression\n",
      "[INFO] - Classifier:  Decision Tree\n",
      "[INFO] - Classifier:  Linear SVM\n",
      "[INFO] - Classifier:  Random Forest\n",
      "[INFO] - Classifier:  AdaBoost\n",
      "[INFO] - Classifier:  Neural Net\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anagharajeev/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] - Classifier:  K-Nearest Neighbours\n",
      "[INFO] - Categorical technique:  Ordinal\n",
      "[INFO] - Classifier:  Logistic Regression\n",
      "[INFO] - Classifier:  Decision Tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rg/7kb02b6n6sq7s0d_dgt_stqm0000gn/T/ipykernel_87388/4137960562.py:39: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  accuracy_per_dataset_df = pandas.concat([accuracy_per_dataset_df, pandas.DataFrame([accuracy_line])], ignore_index=True)\n",
      "/var/folders/rg/7kb02b6n6sq7s0d_dgt_stqm0000gn/T/ipykernel_87388/4137960562.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_accuracy_per_dataset_df = pandas.concat([balanced_accuracy_per_dataset_df, pandas.DataFrame([balanced_accuracy_line])], ignore_index=True)\n",
      "/var/folders/rg/7kb02b6n6sq7s0d_dgt_stqm0000gn/T/ipykernel_87388/4137960562.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  f1_score_per_dataset_df = pandas.concat([f1_score_per_dataset_df, pandas.DataFrame([f1_score_line])], ignore_index=True)\n",
      "/Users/anagharajeev/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] - Classifier:  Linear SVM\n",
      "[INFO] - Classifier:  Random Forest\n",
      "[INFO] - Classifier:  AdaBoost\n",
      "[INFO] - Classifier:  Neural Net\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anagharajeev/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] - Classifier:  K-Nearest Neighbours\n",
      "[INFO] - Categorical technique:  One-hot\n",
      "[INFO] - Classifier:  Logistic Regression\n",
      "[INFO] - Classifier:  Decision Tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anagharajeev/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] - Classifier:  Linear SVM\n",
      "[INFO] - Classifier:  Random Forest\n",
      "[INFO] - Classifier:  AdaBoost\n",
      "[INFO] - Classifier:  Neural Net\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anagharajeev/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] - Classifier:  K-Nearest Neighbours\n"
     ]
    }
   ],
   "source": [
    "categorical_technique_list = [\"Drop Variables\", \"Ordinal\", \"One-hot\"]\n",
    "X_train_list = [drop_X_train,label_X_train,OH_X_train]\n",
    "X_test_list = [drop_X_test,label_X_test,OH_X_test]\n",
    "\n",
    "# accuracy_per_dataset_df = pandas.DataFrame(columns=[\"Dataset Name\"].append(names))\n",
    "# balanced_accuracy_per_dataset_df = pandas.DataFrame(columns=[\"Dataset Name\"].append(names))\n",
    "# f1_score_per_dataset_df = pandas.DataFrame(columns=[\"Dataset Name\"].append(names))\n",
    "\n",
    "#creating empty DFs\n",
    "accuracy_per_dataset_df = pandas.DataFrame(columns=[\"Dataset Name\"] + names)\n",
    "balanced_accuracy_per_dataset_df = pandas.DataFrame(columns=[\"Dataset Name\"] + names)\n",
    "f1_score_per_dataset_df = pandas.DataFrame(columns=[\"Dataset Name\"] + names)\n",
    "\n",
    "# Concatenating the DataFrames\n",
    "accuracy_per_dataset_df = pandas.concat([accuracy_per_dataset_df] * len(names), ignore_index=True)\n",
    "balanced_accuracy_per_dataset_df = pandas.concat([balanced_accuracy_per_dataset_df] * len(names), ignore_index=True)\n",
    "f1_score_per_dataset_df = pandas.concat([f1_score_per_dataset_df] * len(names), ignore_index=True)\n",
    "\n",
    "\n",
    "for technique,X_train,X_test in zip(categorical_technique_list,X_train_list,X_test_list):\n",
    "    print(\"[INFO] - Categorical technique: \", technique)\n",
    "    accuracy_line = {\"Dataset Name\": technique}\n",
    "    balanced_accuracy_line = {\"Dataset Name\": technique}\n",
    "    f1_score_line = {\"Dataset Name\": technique}\n",
    "    \n",
    "    for classifier,method_name in zip(classifiers,names):\n",
    "        print(\"[INFO] - Classifier: \", method_name)\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        Y_pred = classifier.predict(X_test)\n",
    "        accuracy_line[method_name] = accuracy_score(Y_test,Y_pred)\n",
    "        balanced_accuracy_line[method_name] = balanced_accuracy_score(Y_test,Y_pred)\n",
    "        f1_score_line[method_name] = f1_score(Y_test,Y_pred)\n",
    "    \n",
    "    # accuracy_per_dataset_df = accuracy_per_dataset_df.append(accuracy_line,ignore_index=True)\n",
    "    # balanced_accuracy_per_dataset_df = balanced_accuracy_per_dataset_df.append(balanced_accuracy_line,ignore_index=True)\n",
    "    # f1_score_per_dataset_df = f1_score_per_dataset_df.append(f1_score_line,ignore_index=True)\n",
    "        \n",
    "    # Append the lines to the DataFrames\n",
    "    accuracy_per_dataset_df = pandas.concat([accuracy_per_dataset_df, pandas.DataFrame([accuracy_line])], ignore_index=True)\n",
    "    balanced_accuracy_per_dataset_df = pandas.concat([balanced_accuracy_per_dataset_df, pandas.DataFrame([balanced_accuracy_line])], ignore_index=True)\n",
    "    f1_score_per_dataset_df = pandas.concat([f1_score_per_dataset_df, pandas.DataFrame([f1_score_line])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ccc3ec8a-edcd-433e-9f0c-1cea13cb9aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>K-Nearest Neighbours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drop Variables</td>\n",
       "      <td>0.95112</td>\n",
       "      <td>0.95112</td>\n",
       "      <td>0.947047</td>\n",
       "      <td>0.95112</td>\n",
       "      <td>0.948405</td>\n",
       "      <td>0.95112</td>\n",
       "      <td>0.939579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ordinal</td>\n",
       "      <td>0.95112</td>\n",
       "      <td>0.95112</td>\n",
       "      <td>0.948405</td>\n",
       "      <td>0.95112</td>\n",
       "      <td>0.949762</td>\n",
       "      <td>0.95112</td>\n",
       "      <td>0.940258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One-hot</td>\n",
       "      <td>0.95112</td>\n",
       "      <td>0.95112</td>\n",
       "      <td>0.947047</td>\n",
       "      <td>0.95112</td>\n",
       "      <td>0.951120</td>\n",
       "      <td>0.95112</td>\n",
       "      <td>0.938900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset Name  Logistic Regression  Decision Tree  Linear SVM  \\\n",
       "0  Drop Variables              0.95112        0.95112    0.947047   \n",
       "1         Ordinal              0.95112        0.95112    0.948405   \n",
       "2         One-hot              0.95112        0.95112    0.947047   \n",
       "\n",
       "   Random Forest  AdaBoost  Neural Net  K-Nearest Neighbours  \n",
       "0        0.95112  0.948405     0.95112              0.939579  \n",
       "1        0.95112  0.949762     0.95112              0.940258  \n",
       "2        0.95112  0.951120     0.95112              0.938900  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_per_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "10c6ff6a-641a-43a5-be54-eeec435e9477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>K-Nearest Neighbours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drop Variables</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.504446</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.498572</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ordinal</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.498572</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.499286</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One-hot</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.504446</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset Name  Logistic Regression  Decision Tree  Linear SVM  \\\n",
       "0  Drop Variables                  0.5            0.5    0.504446   \n",
       "1         Ordinal                  0.5            0.5    0.498572   \n",
       "2         One-hot                  0.5            0.5    0.504446   \n",
       "\n",
       "   Random Forest  AdaBoost  Neural Net  K-Nearest Neighbours  \n",
       "0            0.5  0.498572         0.5              0.500520  \n",
       "1            0.5  0.499286         0.5              0.500877  \n",
       "2            0.5  0.500000         0.5              0.500164  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_per_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "181588b3-97b9-4c01-a5dd-85f3d9a505ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>K-Nearest Neighbours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drop Variables</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ordinal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One-hot</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset Name  Logistic Regression  Decision Tree  Linear SVM  \\\n",
       "0  Drop Variables                  0.0            0.0       0.025   \n",
       "1         Ordinal                  0.0            0.0       0.000   \n",
       "2         One-hot                  0.0            0.0       0.025   \n",
       "\n",
       "   Random Forest  AdaBoost  Neural Net  K-Nearest Neighbours  \n",
       "0            0.0       0.0         0.0              0.021978  \n",
       "1            0.0       0.0         0.0              0.022222  \n",
       "2            0.0       0.0         0.0              0.021739  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_per_dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283a6370-fe3e-491d-9dad-c448f854f6f1",
   "metadata": {},
   "source": [
    "## Activity 1.7\n",
    "\n",
    "Congratulations! By now you should be able to train, test and evaluate multiple models on a classification task.\n",
    "\n",
    "1. Have a look at the documentation of the [Scikit-learn](https://scikit-learn.org/stable/index.html) library for the different parameters of other classification models.\n",
    "\n",
    "2. Analyze the impact of different changes in the predictive setup on the model:\n",
    "- Does the amount of data in the training set affect the predictive performance? Try to apply the procedure by varying the training-test proportion.\n",
    "- Does the parameter setting of the different models have an impact on the model performances? Try to tweak the performance by varying the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36132f00-8f90-41c0-9657-1f34688dc595",
   "metadata": {},
   "source": [
    "# Predictive Analytics - Regression\n",
    "\n",
    "The regression task we will be tackling is based on the [Medical Cost Personal Dataset](https://www.kaggle.com/datasets/mirichoi0218/insurance?ref=hackernoon.com&select=insurance.csv).\n",
    "\n",
    "In this case, we will use the available data to try to predict the insurance cost (`charges` variable) as a function of the other variables.\n",
    "\n",
    "Before starting the modeling task, please have a look at the metadata about the [Medical Cost Personal Dataset](https://www.kaggle.com/datasets/mirichoi0218/insurance?ref=hackernoon.com&select=insurance.csv), in order to better understand the meaning of the different variables.\n",
    "\n",
    "## Activity 2.1 - Descriptive analytics\n",
    "\n",
    "We are going to use the `pandas` library to perform some exploratory understanding of the data.\n",
    "\n",
    "1. Load the dataset in the `insurance_df` variable\n",
    "2. Display the content of the `insurance_df` variable\n",
    "3. What are the type of the different columns? Use the knowledge from `pandas` to determine the type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cf67288b-602f-414e-933a-552ed944c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_df = pandas.read_csv(\"insurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c04de6a0-e38f-4ee8-a4ce-83b5170d54e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3a7418a8-5367-4a5c-8dec-f9395a24ddfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "insurance_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f41a5b-8f72-46eb-87c1-bb3e8562d1db",
   "metadata": {},
   "source": [
    "## Activity 2.2 - Diagnostic analytics\n",
    "\n",
    "A common problem in many datasets is missing data, usually indicated by N/A, NA, NaN, and extreme values (outliers).\n",
    "\n",
    "As a reminder, several ways exist to deal with incomplete or missing data, the most common being:\n",
    "\n",
    "![MissingData](figures/MissingData.png)\n",
    "\n",
    "**Source:** *Skarga-Bandurova, I., Biloborodova, T., & Dyachenko, Y. (2018). Strategy to managing mixed datasets with missing items. In Information Processing and Management of Uncertainty in Knowledge-Based Systems. Theory and Foundations: 17th International Conference, IPMU 2018, Cádiz, Spain, June 11-15, 2018, Proceedings, Part II 17 (pp. 608-620). Springer International Publishing.*\n",
    "\n",
    "\n",
    "1. Is there any column containing missing data in this dataset?\n",
    "2. If there are any, display the column(s) containing missing data.\n",
    "3. Count the number of missing values in the column(s) containing missing data.\n",
    "4. Analyze the missing values and their potential causes, and propose the most appropriate way to process them in order to have a dataset without missing values for the further steps.\n",
    "5. Produce a new dataset `insurance_noNA_df` containing no missing values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a159e5e-c180-4f37-8331-f6570324234f",
   "metadata": {},
   "source": [
    "As there are no missing values, we can use the original dataset as is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d5ace074-87d3-40d7-b3cb-2e0e47e69d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_noNA_df = insurance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d98c7d-ae75-491f-8343-6aaa2a5ca926",
   "metadata": {},
   "source": [
    "## Activity 2.3\n",
    "\n",
    "In order to apply a Machine Learning predictive model on the [Stroke Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset?select=healthcare-dataset-stroke-data.csv) that we had previously imported in the `stroke_df` variable, we need to perform the following operations:\n",
    "\n",
    "1. Impute missing values (Done in 2.2 by dropping/imputing the missing values)\n",
    "2. Split data into training and test using the `train_test_split` function (2.3)\n",
    "3. Transform categorical variables (2.4)\n",
    "\n",
    "**N.B.**: Please note that the transformation in categorical variables needs to be done after the split into training and test set in order to avoid information leakage (normally the testing set should not be seen by the model during its training phase).\n",
    "\n",
    "We are going to use the `scikit-learn` library to perform most of the split and transformation tasks.\n",
    "\n",
    "Here you need to:\n",
    "1. Divide the `insurance_noNA_df` dataset into two variables:\n",
    "- `X` containing the input variables\n",
    "- `Y` containing the target variable (`charges`)\n",
    "2. Use the `train_test_split` function to obtain `X_train, X_test, Y_train, Y_test` with a 70% train - 30% test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d5bca92b-ca3d-4522-ac72-a1e3a280e2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = insurance_noNA_df.iloc[:,0:6]\n",
    "Y = insurance_noNA_df.iloc[:,6]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc2006e-5385-4e4c-8213-b4410b3f00e6",
   "metadata": {},
   "source": [
    "## Activity 2.4\n",
    "\n",
    "Before inputting the data to a Machine Learning model, we need all the inputs to be numeric.\n",
    "In order to transform categorical data into numeric ones, three techniques exist (cf. https://www.kaggle.com/code/alexisbcook/categorical-variables):\n",
    "- Dropping Categorical variables\n",
    "- Ordinal Encoding: A categorical variable is replaced by a single numerical variable, where each category is mapped to a different, increasing integer value.\n",
    "- One-hot Encoding: A categorical variable with $n$ different categories is replaced by $n$ binary variables, each of them corresponding to a category. \n",
    "\n",
    "We are going to use the `scikit-learn` library to perform the transformation of the variables and to subsequently fit the models.\n",
    "\n",
    "1. Have a look at the documentation of the [Scikit-learn](https://scikit-learn.org/stable/index.html) library \n",
    "2. Have a look at the following code to perform the transformation of categorical variables:\n",
    "- Dropping Categorical variables: `drop_X_train` and `drop_X_test`\n",
    "- Ordinal Encoding: `label_X_train` and `label_X_test`\n",
    "- One-hot Encoding: `OH_X_train` and `OH_X_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "142a6f3d-86f8-434a-9b56-9eb71902e63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical variables:\n",
      "['sex', 'smoker', 'region']\n"
     ]
    }
   ],
   "source": [
    "# Get list of categorical variables\n",
    "s = (X_train.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "print(\"Categorical variables:\")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f7cdbd-3326-406f-8b97-ee2e3701be12",
   "metadata": {},
   "source": [
    "### Dropping categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "47f64b96-52d5-41b7-8c7c-7d340bc1499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_test = X_test.select_dtypes(exclude=['object'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a95094c-fe41-49ba-9881-f893d798b161",
   "metadata": {},
   "source": [
    "### Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6971f9a6-b15a-4456-a6bc-ed006f9883e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Make copy to avoid changing original data \n",
    "label_X_train = X_train.copy()\n",
    "label_X_test = X_test.copy()\n",
    "\n",
    "# Apply ordinal encoder to each column with categorical data\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "label_X_train[object_cols] = ordinal_encoder.fit_transform(X_train[object_cols])\n",
    "label_X_test[object_cols] = ordinal_encoder.transform(X_test[object_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b052fa3c-2c70-42c8-b1ff-dd04cfce9957",
   "metadata": {},
   "source": [
    "### One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f9e2cce8-38c8-4d2c-b6e0-d544f8a9d2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_train = pandas.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\n",
    "OH_cols_test = pandas.DataFrame(OH_encoder.transform(X_test[object_cols]))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_test = X_test.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pandas.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_test = pandas.concat([num_X_test, OH_cols_test], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c076fe77-7c4d-419a-a30e-19cf6b381abe",
   "metadata": {},
   "source": [
    "## Activity 2.5\n",
    "\n",
    "Finally, with the data cleaned of missing values, and with the categorical variables appropriately transformed we are able to fit some models using the `scikit-learn` library.\n",
    "\n",
    "As seen in Lecture 5 a starter, we will will be using a baseline for regression models: a [Linear Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)\n",
    "\n",
    "1. Have a look at the documentation of the [Scikit-learn](https://scikit-learn.org/stable/index.html) library for the Linear Regression model.\n",
    "2. Initialize the model\n",
    "3. Use the `fit` function to perform the training of the model on the training set.\n",
    "4. Use the `predict` function to perform the prediction of the model on the test set.\n",
    "5. Use the `mean_squared_error, mean_absolute_error, mean_absolute_percentage_error` to compare the predictions with the actual values and obtain different performance metrics about the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "883b3cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_test.columns = OH_X_test.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ab36efcf-4756-47d4-901b-dd38ad824a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (Dropped categorical):  127399626.37416688\n",
      "MAE (Dropped categorical):  9079.649028580896\n",
      "MAPE (Dropped categorical):  1.1825368635705567\n",
      "MSE (Ordinal encoding):  33805466.898688614\n",
      "MAE (Ordinal encoding):  4155.239843059382\n",
      "MAPE (Ordinal encoding):  0.44125939462651353\n",
      "MSE (One-hot encoding):  33780509.57479163\n",
      "MAE (One-hot encoding):  4145.450555627585\n",
      "MAPE (One-hot encoding):  0.43585625991943105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(drop_X_train, Y_train)\n",
    "Y_pred = lr.predict(drop_X_test)\n",
    "print(\"MSE (Dropped categorical): \", mean_squared_error(Y_test, Y_pred))\n",
    "print(\"MAE (Dropped categorical): \", mean_absolute_error(Y_test, Y_pred))\n",
    "print(\"MAPE (Dropped categorical): \", mean_absolute_percentage_error(Y_test, Y_pred))\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(label_X_train, Y_train)\n",
    "Y_pred = lr.predict(label_X_test)\n",
    "print(\"MSE (Ordinal encoding): \", mean_squared_error(Y_test, Y_pred))\n",
    "print(\"MAE (Ordinal encoding): \", mean_absolute_error(Y_test, Y_pred))\n",
    "print(\"MAPE (Ordinal encoding): \", mean_absolute_percentage_error(Y_test, Y_pred))\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(OH_X_train, Y_train)\n",
    "Y_pred = lr.predict(OH_X_test)\n",
    "print(\"MSE (One-hot encoding): \", mean_squared_error(Y_test, Y_pred))\n",
    "print(\"MAE (One-hot encoding): \", mean_absolute_error(Y_test, Y_pred))\n",
    "print(\"MAPE (One-hot encoding): \", mean_absolute_percentage_error(Y_test, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a0ed3f-7a4a-4431-a0b5-6530a2d50872",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Activity 2.6\n",
    "\n",
    "Now that you are familiar with the pipeline of training, testing and evaluating one model, you can easily repeat the procedure for multiple models.\n",
    "\n",
    "1. Have a look at the documentation of the [Scikit-learn](https://scikit-learn.org/stable/index.html) library for other regression models:\n",
    "    - Lasso/ElasticNet\n",
    "    - Decision Tree\n",
    "    - Random Forest\n",
    "    - Gradient Boosting\n",
    "    - Artificial Neural Networks\n",
    "    - K-Nearest Neighbors\n",
    "2. For each model:\n",
    "    1. Initialize the model\n",
    "    2. Use the `fit` function to perform the training of the model on the training set\n",
    "    3. Use the `predict` function to perform the prediction of the model on the test set\n",
    "    4. Use the `accuracy_score, balanced_accuracy_score, f1_score` to compare the predictions with the actual values and obtain performance metrics about the models.\n",
    "    \n",
    "3. Create a dictionary/Data Frame in order to be able to compare the performance scores of the different models.\n",
    "    1. Are there any differences in the values of the metrics?\n",
    "    2. Why are these values different? Check the documentation to get to know more about the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5b106aab-a4a8-4ae2-bd8c-a87303f83917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "names = [\n",
    "    \"Lasso\",\n",
    "    \"Elastic Net\",\n",
    "    \"Linear SVM\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"AdaBoost\",\n",
    "    \"Neural Net\",\n",
    "    \"K-Nearest Neighbours\"\n",
    "]\n",
    "\n",
    "regressors = [\n",
    "    Lasso(alpha=0.1),\n",
    "    ElasticNet(random_state=0),\n",
    "    SVR(kernel=\"linear\", C=0.025),\n",
    "    DecisionTreeRegressor(max_depth=5),\n",
    "    RandomForestRegressor(max_depth=5, n_estimators=10, max_features=1),\n",
    "    AdaBoostRegressor(),\n",
    "    MLPRegressor(alpha=1, max_iter=1000),\n",
    "    KNeighborsRegressor(3),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1bb6ec50-32da-469d-a9b2-c949ba0cbfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] - Categorical technique:  Drop Variables\n",
      "[INFO] - Regressor:  Lasso\n",
      "[INFO] - Regressor:  Elastic Net\n",
      "[INFO] - Regressor:  Linear SVM\n",
      "[INFO] - Regressor:  Decision Tree\n",
      "[INFO] - Regressor:  Random Forest\n",
      "[INFO] - Regressor:  AdaBoost\n",
      "[INFO] - Regressor:  Neural Net\n",
      "[INFO] - Regressor:  K-Nearest Neighbours\n",
      "[INFO] - Categorical technique:  Ordinal\n",
      "[INFO] - Regressor:  Lasso\n",
      "[INFO] - Regressor:  Elastic Net\n",
      "[INFO] - Regressor:  Linear SVM\n",
      "[INFO] - Regressor:  Decision Tree\n",
      "[INFO] - Regressor:  Random Forest\n",
      "[INFO] - Regressor:  AdaBoost\n",
      "[INFO] - Regressor:  Neural Net\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rg/7kb02b6n6sq7s0d_dgt_stqm0000gn/T/ipykernel_87388/4277589396.py:37: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  MSE_per_dataset_df = pandas.concat([MSE_per_dataset_df, pandas.DataFrame([MSE_line])], ignore_index=True)\n",
      "/var/folders/rg/7kb02b6n6sq7s0d_dgt_stqm0000gn/T/ipykernel_87388/4277589396.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  MAE_per_dataset_df = pandas.concat([MAE_per_dataset_df, pandas.DataFrame([MAE_line])], ignore_index=True)\n",
      "/var/folders/rg/7kb02b6n6sq7s0d_dgt_stqm0000gn/T/ipykernel_87388/4277589396.py:39: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  MAPE_per_dataset_df = pandas.concat([MAPE_per_dataset_df, pandas.DataFrame([MAPE_line])], ignore_index=True)\n",
      "/Users/anagharajeev/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] - Regressor:  K-Nearest Neighbours\n",
      "[INFO] - Categorical technique:  One-hot\n",
      "[INFO] - Regressor:  Lasso\n",
      "[INFO] - Regressor:  Elastic Net\n",
      "[INFO] - Regressor:  Linear SVM\n",
      "[INFO] - Regressor:  Decision Tree\n",
      "[INFO] - Regressor:  Random Forest\n",
      "[INFO] - Regressor:  AdaBoost\n",
      "[INFO] - Regressor:  Neural Net\n",
      "[INFO] - Regressor:  K-Nearest Neighbours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anagharajeev/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "categorical_technique_list = [\"Drop Variables\", \"Ordinal\", \"One-hot\"]\n",
    "X_train_list = [drop_X_train,label_X_train,OH_X_train]\n",
    "X_test_list = [drop_X_test,label_X_test,OH_X_test]\n",
    "\n",
    "# MSE_per_dataset_df = pandas.DataFrame(columns=[\"Dataset Name\"].append(names))\n",
    "# MAE_per_dataset_df = pandas.DataFrame(columns=[\"Dataset Name\"].append(names))\n",
    "# MAPE_per_dataset_df = pandas.DataFrame(columns=[\"Dataset Name\"].append(names))\n",
    "\n",
    "# Creating empty DataFrames\n",
    "MSE_per_dataset_df = pandas.DataFrame(columns=[\"Dataset Name\"] + names)\n",
    "MAE_per_dataset_df = pandas.DataFrame(columns=[\"Dataset Name\"] + names)\n",
    "MAPE_per_dataset_df = pandas.DataFrame(columns=[\"Dataset Name\"] + names)\n",
    "\n",
    "# Concatenating the DataFrames\n",
    "MSE_per_dataset_df = pandas.concat([MSE_per_dataset_df] * len(names), ignore_index=True)\n",
    "MAE_per_dataset_df = pandas.concat([MAE_per_dataset_df] * len(names), ignore_index=True)\n",
    "MAPE_per_dataset_df = pandas.concat([MAPE_per_dataset_df] * len(names), ignore_index=True)\n",
    "\n",
    "for technique,X_train,X_test in zip(categorical_technique_list,X_train_list,X_test_list):\n",
    "    print(\"[INFO] - Categorical technique: \", technique)\n",
    "    MSE_line = {\"Dataset Name\": technique}\n",
    "    MAE_line = {\"Dataset Name\": technique}\n",
    "    MAPE_line = {\"Dataset Name\": technique}\n",
    "    \n",
    "    for regressor,method_name in zip(regressors,names):\n",
    "        print(\"[INFO] - Regressor: \", method_name)\n",
    "        regressor.fit(X_train, Y_train)\n",
    "        Y_pred = regressor.predict(X_test)\n",
    "        MSE_line[method_name] = mean_squared_error(Y_test, Y_pred)\n",
    "        MAE_line[method_name] = mean_absolute_error(Y_test, Y_pred)\n",
    "        MAPE_line[method_name] = mean_absolute_percentage_error(Y_test, Y_pred)\n",
    "    \n",
    "    # MSE_per_dataset_df = MSE_per_dataset_df.append(MSE_line,ignore_index=True)\n",
    "    # MAE_per_dataset_df = MAE_per_dataset_df.append(MAE_line,ignore_index=True)\n",
    "    # MAPE_per_dataset_df = MAPE_per_dataset_df.append(MAPE_line,ignore_index=True)\n",
    "    # Append the lines to the DataFrames\n",
    "    MSE_per_dataset_df = pandas.concat([MSE_per_dataset_df, pandas.DataFrame([MSE_line])], ignore_index=True)\n",
    "    MAE_per_dataset_df = pandas.concat([MAE_per_dataset_df, pandas.DataFrame([MAE_line])], ignore_index=True)\n",
    "    MAPE_per_dataset_df = pandas.concat([MAPE_per_dataset_df, pandas.DataFrame([MAPE_line])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "58eb96b3-6925-4d47-a998-9c52e47b3368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>Elastic Net</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>K-Nearest Neighbours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drop Variables</td>\n",
       "      <td>1.273996e+08</td>\n",
       "      <td>1.272845e+08</td>\n",
       "      <td>1.596486e+08</td>\n",
       "      <td>1.554137e+08</td>\n",
       "      <td>1.332995e+08</td>\n",
       "      <td>1.540228e+08</td>\n",
       "      <td>1.292610e+08</td>\n",
       "      <td>1.644835e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ordinal</td>\n",
       "      <td>3.380547e+07</td>\n",
       "      <td>8.730325e+07</td>\n",
       "      <td>1.596246e+08</td>\n",
       "      <td>2.086958e+07</td>\n",
       "      <td>4.189609e+07</td>\n",
       "      <td>2.620102e+07</td>\n",
       "      <td>1.229605e+08</td>\n",
       "      <td>1.315094e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One-hot</td>\n",
       "      <td>3.378068e+07</td>\n",
       "      <td>6.880285e+07</td>\n",
       "      <td>1.595551e+08</td>\n",
       "      <td>2.095733e+07</td>\n",
       "      <td>3.289737e+07</td>\n",
       "      <td>2.482701e+07</td>\n",
       "      <td>1.152293e+08</td>\n",
       "      <td>1.057710e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset Name         Lasso   Elastic Net    Linear SVM  Decision Tree  \\\n",
       "0  Drop Variables  1.273996e+08  1.272845e+08  1.596486e+08   1.554137e+08   \n",
       "1         Ordinal  3.380547e+07  8.730325e+07  1.596246e+08   2.086958e+07   \n",
       "2         One-hot  3.378068e+07  6.880285e+07  1.595551e+08   2.095733e+07   \n",
       "\n",
       "   Random Forest      AdaBoost    Neural Net  K-Nearest Neighbours  \n",
       "0   1.332995e+08  1.540228e+08  1.292610e+08          1.644835e+08  \n",
       "1   4.189609e+07  2.620102e+07  1.229605e+08          1.315094e+08  \n",
       "2   3.289737e+07  2.482701e+07  1.152293e+08          1.057710e+08  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_per_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "393494be-cd97-46d9-9574-4b53bbcdb10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>Elastic Net</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>K-Nearest Neighbours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drop Variables</td>\n",
       "      <td>9079.650755</td>\n",
       "      <td>9083.953829</td>\n",
       "      <td>7086.288501</td>\n",
       "      <td>9351.948069</td>\n",
       "      <td>9089.105148</td>\n",
       "      <td>11121.295617</td>\n",
       "      <td>9182.722541</td>\n",
       "      <td>9069.469601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ordinal</td>\n",
       "      <td>4155.272559</td>\n",
       "      <td>7322.318781</td>\n",
       "      <td>7085.098638</td>\n",
       "      <td>2670.427244</td>\n",
       "      <td>4902.308131</td>\n",
       "      <td>4110.065489</td>\n",
       "      <td>8951.151441</td>\n",
       "      <td>7420.412707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One-hot</td>\n",
       "      <td>4145.507331</td>\n",
       "      <td>6299.410887</td>\n",
       "      <td>7084.326374</td>\n",
       "      <td>2672.988491</td>\n",
       "      <td>4264.514947</td>\n",
       "      <td>3780.938608</td>\n",
       "      <td>8619.774231</td>\n",
       "      <td>6225.511141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset Name        Lasso  Elastic Net   Linear SVM  Decision Tree  \\\n",
       "0  Drop Variables  9079.650755  9083.953829  7086.288501    9351.948069   \n",
       "1         Ordinal  4155.272559  7322.318781  7085.098638    2670.427244   \n",
       "2         One-hot  4145.507331  6299.410887  7084.326374    2672.988491   \n",
       "\n",
       "   Random Forest      AdaBoost   Neural Net  K-Nearest Neighbours  \n",
       "0    9089.105148  11121.295617  9182.722541           9069.469601  \n",
       "1    4902.308131   4110.065489  8951.151441           7420.412707  \n",
       "2    4264.514947   3780.938608  8619.774231           6225.511141  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE_per_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f74d612b-4b98-4b9d-9db8-13427b8b16a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>Elastic Net</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>K-Nearest Neighbours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drop Variables</td>\n",
       "      <td>1.182540</td>\n",
       "      <td>1.190088</td>\n",
       "      <td>0.557398</td>\n",
       "      <td>1.236815</td>\n",
       "      <td>1.279493</td>\n",
       "      <td>1.850150</td>\n",
       "      <td>1.285927</td>\n",
       "      <td>1.192442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ordinal</td>\n",
       "      <td>0.441262</td>\n",
       "      <td>0.950017</td>\n",
       "      <td>0.557056</td>\n",
       "      <td>0.307797</td>\n",
       "      <td>0.738643</td>\n",
       "      <td>0.681650</td>\n",
       "      <td>1.254400</td>\n",
       "      <td>0.793421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One-hot</td>\n",
       "      <td>0.435868</td>\n",
       "      <td>0.815184</td>\n",
       "      <td>0.557314</td>\n",
       "      <td>0.308484</td>\n",
       "      <td>0.708845</td>\n",
       "      <td>0.567752</td>\n",
       "      <td>1.198214</td>\n",
       "      <td>0.591876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset Name     Lasso  Elastic Net  Linear SVM  Decision Tree  \\\n",
       "0  Drop Variables  1.182540     1.190088    0.557398       1.236815   \n",
       "1         Ordinal  0.441262     0.950017    0.557056       0.307797   \n",
       "2         One-hot  0.435868     0.815184    0.557314       0.308484   \n",
       "\n",
       "   Random Forest  AdaBoost  Neural Net  K-Nearest Neighbours  \n",
       "0       1.279493  1.850150    1.285927              1.192442  \n",
       "1       0.738643  0.681650    1.254400              0.793421  \n",
       "2       0.708845  0.567752    1.198214              0.591876  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAPE_per_dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec2ce23-4404-46f1-9afe-fd62b38c948d",
   "metadata": {},
   "source": [
    "## Activity 2.7\n",
    "\n",
    "Congratulations! By now you should be able to train, test and evaluate multiple models on a classification task.\n",
    "\n",
    "1. Have a look at the documentation of the [Scikit-learn](https://scikit-learn.org/stable/index.html) library for the different parameters of other classification models.\n",
    "\n",
    "2. Analyze the impact of different changes in the predictive setup on the model:\n",
    "- Does the amount of data in the training set affect the predictive performance? Try to apply the procedure by varying the training-test proportion.\n",
    "- Does the parameter setting of the different models have an impact on the model performances? Try to tweak the performance by varying the parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
