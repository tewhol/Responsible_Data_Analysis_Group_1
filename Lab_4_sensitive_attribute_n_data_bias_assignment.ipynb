{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8uT-aSmIU0t"
      },
      "source": [
        "# Lab 4 - Sensitive Attributes and Data Bias\n",
        "Week 4 - Q3, 23/24 <br>\n",
        "SEN163B: Responsible Data Analytics<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1UeTKVmIU0t"
      },
      "source": [
        "By <b> Sepinoud Azimi Rashti* </b> <br>\n",
        "TA <b> Darsh Modi</b> <br>\n",
        "Faculty of Technology, Policy, and Management (TPM)<br>\n",
        "\n",
        "<small>*Acknowledgement: Part of this lab is loosely based on the code developed by <i><b>Agathe Balayn</b></i> and <i><b>Seda Gürses</b>. Notebook made by <b>Nadia Metoui</b></i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKPwVwVyIU0t"
      },
      "source": [
        "***Learning Objectives***<br>\n",
        "At the end of this lab, you will be able to\n",
        "\n",
        "- Use data analytics tools to identify Sensitive attributes and proxies\n",
        "- Use data analytics tools to identify Representation Bias\n",
        "- Use data analytics tools to identify Historical Bias\n",
        "- Understanding, Analyse and Discuss Historical, Representation and Measurement Biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUa9W6KW3qct"
      },
      "source": [
        "***Structure***\n",
        "- Part I. Understanding the Use Case\n",
        "- Part II Protected attributes, proxies\n",
        "- Part III: Representation Disparities, Skew and Bias\n",
        "- Part IV. Discuss Measurement Bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz9ydppeIU0u"
      },
      "source": [
        "<H2> </H2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuGfHB25Ltha"
      },
      "source": [
        "## Part I. Understanding the Use Case"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6FMhDtrIU0u"
      },
      "source": [
        "<b>Use Case Description</b> In this Lab you will be exploring a use case where a Bank wants to develop an ML-based data product in the form of ADM (automate decision system) to decide whether to <b>grant</b> or <b>not to grant</b> a loan to a given applicant. To do so the Bank uses historical data containing multiple application records, characterized by information about the loan applicants (e.g., age, gender, personal situation) and information about the loan (e.g., amount, duration, purpose). Each application is labeled <i><b> good credit </b></i> if the loan had been reimbursed or <i><b>bad credit</b></i> if the loan has not been reimbursed or if there where several issues with the reimbursement.\n",
        "\n",
        "During this lab we will not concern our selves yet with developping (coding) the data analytics product itslef.\n",
        "We will rather explore the data using data analytics tools then reflect on three categories of Bias inspired by (Suresh and Guttag 2019)\n",
        "- <i>Historical Bias</i>: Case Analysis, Sensitive attributes, Data skew\n",
        "- <i>Representation Bias</i>: Case Analysis, Sensitive attributes, Distributions\n",
        "- <i>Measurement Bias</i>: Case Analysis\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_g92GbKf02o"
      },
      "source": [
        "\n",
        "<i><b>German credit dataset</b></i> contains 1000 entries with 20 attributes (7 numerical, 13 categorical) prepared by Prof. Hofmann. We will use the version hosted in the <a href=\"https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)\">UCI Machine Learning Archive</a>.<br>\n",
        "\n",
        "In this dataset, each entry represents a person who took a credit from a german bank. We have no information about the date/year of the data collcetion. However, for the sake of this exercise, we will assume the data was collected in 2018.  \n",
        "\n",
        "You can download the dataset here: https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data<br>\n",
        "\n",
        "The original data is encoded in a complex way. You can find information about the dataset and its attributes here: (https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc).<br>\n",
        "\n",
        "We also provide you with the code to preprocess the data in more comprehensive attributes and featuers.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWv8AeWyjCJm"
      },
      "source": [
        "Analysis Steps\n",
        "- Step 1: Set-up (Provided)\n",
        "- Step 2: Explore and familiarize with the dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UYkPwm5IU0v"
      },
      "source": [
        "### Setp 1: Set-up\n",
        "\n",
        "You first need load (usually no installation is needed) the required libraries for this part.  The main libraries are `numpy`, `pandas`, `matplotlib` and `seaborn`. We recommend using these to easily manipulate and explore the data but you are free to use any other libraries you are more familar with.\n",
        "\n",
        "We will introduce the data visualization tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnqQI4-xIU0v"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\">\n",
        "<b>Note:</b> Uncomment and run the next cell if you have not previously installed the libraries.\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0k-Qw20IU0v"
      },
      "source": [
        "<b>Installing required libraries</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4vG8dTvIU0w",
        "outputId": "ec74d09d-5be6-4690-f09f-8d0ef0fa5d88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: aif360 in /usr/local/lib/python3.8/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.8/dist-packages (from aif360) (1.22.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from aif360) (3.5.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.8/dist-packages (from aif360) (1.2.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from aif360) (1.10.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from aif360) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->aif360) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->aif360) (2022.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0->aif360) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0->aif360) (1.2.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->aif360) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->aif360) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->aif360) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->aif360) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->aif360) (23.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->aif360) (4.38.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->aif360) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "# If you need to install any new libraries, add the code here\n",
        "\n",
        "# install AIF 360 Toolkit\n",
        "!pip install aif360\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vShFtuezIU0w"
      },
      "source": [
        "<b>Loading required libraries</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiHQY_LCIU0w",
        "outputId": "adb60177-5942-43e7-d687-84275af31377"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
            "pip install 'aif360[LawSchoolGPA]'\n"
          ]
        }
      ],
      "source": [
        "# Libraries for data processing and visualiztion\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "\n",
        "# we will use the Faireness Tool IBM AI Fairness 360 only to help formatting the german data set\n",
        "# Please ignore this at the moment we will learn more about it in Week 6\n",
        "from aif360.datasets import GermanDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zF_POAMRd3I"
      },
      "source": [
        "<b>Download the German Credit Data set</b><br>\n",
        "In the following we will download the data set and https://archive.ics.uci.edu its documentation from the website and place it in the correct. At this point in the course you should be able to do this on your own. But we provide some code to guide students who still need some help. Feel free to use, modify or discard this code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GWW3vXKSo6Z"
      },
      "source": [
        "**Option 1 Google Colab:**<br>\n",
        "Uncomment the following cell to download the dataset in google colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mcNotjsPyjZ",
        "outputId": "832451a3-fb8f-4e30-bbaa-1cc81b65db8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-03-08 11:11:01--  https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 79793 (78K) [application/x-httpd-php]\n",
            "Saving to: ‘german.data.3’\n",
            "\n",
            "\rgerman.data.3         0%[                    ]       0  --.-KB/s               \rgerman.data.3       100%[===================>]  77.92K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-03-08 11:11:02 (3.53 MB/s) - ‘german.data.3’ saved [79793/79793]\n",
            "\n",
            "--2023-03-08 11:11:02--  https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4679 (4.6K) [application/x-httpd-php]\n",
            "Saving to: ‘german.doc.3’\n",
            "\n",
            "german.doc.3        100%[===================>]   4.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-03-08 11:11:02 (148 MB/s) - ‘german.doc.3’ saved [4679/4679]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Download the German Credit DataSet\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc\n",
        "!cp german.data /usr/local/lib/python3.8/dist-packages/aif360/data/raw/german/german.data\n",
        "!cp german.doc /usr/local/lib/python3.8/dist-packages/aif360/data/raw/german/german.doc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCKBANQFSY_G"
      },
      "source": [
        "**Option 2: Local environment**<br>\n",
        "<div class=\"alert alert-block alert-danger\">\n",
        "<b>Note:</b> If you are working on your local environment you will have to manually add the files \"german.doc\" and \"german.data\" to the folder\n",
        "\"dist-packages/aif360/data/raw/german/\" under your python path.<br>\n",
        "(or write your script to do it deppending on the os/platform you are using)\n",
        "You can find the files in the lab folder on github or download them from: <br>\n",
        "<a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\">https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data</a> <br>\n",
        "<a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc\">https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc</a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S7flKyCIU0x"
      },
      "source": [
        "<b>Loading the dataset</b>\n",
        "\n",
        "Here, we will load the <i><b>German credit data</b></i> in a format that is compatible with the use of the <i><b>AIF360 toolkit</b></i>. For this, you need to make use of the already implemented class of the toolkit `GermanDataset()`.\n",
        "\n",
        "Because the data available is encoded in a complex way, we provide you with the code to preprocess it, in the function `custom_preprocessing()`. We also provide you with an example on how to actually load the data using the `GermanDataset()` class, in `preproc_and_load_data_german()`.\n",
        "\n",
        "<small>*Note: We are not making use of AIF360 toolkit yet we will do it on week 6*</small>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViJlrVIzIU0x"
      },
      "outputs": [],
      "source": [
        "def preproc_and_load_data_german():\n",
        "    \"\"\"\n",
        "    Load and pre-process german credit dataset.\n",
        "    Args: -\n",
        "    Returns:\n",
        "        GermanDataset: An instance of GermanDataset with required pre-processing.\n",
        "    \"\"\"\n",
        "    def custom_preprocessing(df):\n",
        "        \"\"\" Custom pre-processing for German Credit Data\n",
        "        \"\"\"\n",
        "\n",
        "        def group_credit_hist(x):\n",
        "            if x in ['A30', 'A31', 'A32']:\n",
        "                return 'None/Paid'\n",
        "            elif x == 'A33':\n",
        "                return 'Delay'\n",
        "            elif x == 'A34':\n",
        "                return 'Other'\n",
        "            else:\n",
        "                return 'NA'\n",
        "\n",
        "        def group_employ(x):\n",
        "            if x == 'A71':\n",
        "                return 'Unemployed'\n",
        "            elif x in ['A72', 'A73']:\n",
        "                return '1-4 years'\n",
        "            elif x in ['A74', 'A75']:\n",
        "                return '4+ years'\n",
        "            else:\n",
        "                return 'NA'\n",
        "\n",
        "        def group_savings(x):\n",
        "            if x in ['A61', 'A62']:\n",
        "                return '<500'\n",
        "            elif x in ['A63', 'A64']:\n",
        "                return '500+'\n",
        "            elif x == 'A65':\n",
        "                return 'Unknown/None'\n",
        "            else:\n",
        "                return 'NA'\n",
        "\n",
        "        def group_status(x):\n",
        "            if x in ['A11', 'A12']:\n",
        "                return '<200'\n",
        "            elif x in ['A13']:\n",
        "                return '200+'\n",
        "            elif x == 'A14':\n",
        "                return 'None'\n",
        "            else:\n",
        "                return 'NA'\n",
        "\n",
        "        def group_personal_status(x):\n",
        "            if x in ['A91']:\n",
        "                return 'divorced/separated'\n",
        "            elif x in ['A92']:\n",
        "                return 'divorced/separated/married'\n",
        "            elif x in ['A93', 'A95']:\n",
        "                return 'single'\n",
        "            elif x in ['A94']:\n",
        "                return 'married/widowed'\n",
        "            else:\n",
        "                return 'NA'\n",
        "\n",
        "        def group_foreign_worker(x):\n",
        "            if x in ['A201']:\n",
        "                return 'yes'\n",
        "            elif x in ['A202']:\n",
        "                return 'no'\n",
        "            else:\n",
        "                return 'NA'\n",
        "\n",
        "        #print(df)\n",
        "        #print(df.shape)\n",
        "        #print(df.isnull().sum().sum())\n",
        "        #print(df.isin(['NA']).sum(axis=0))\n",
        "        status_map = {'A91': 1.0, 'A93': 1.0, 'A94': 1.0,\n",
        "                    'A92': 0.0, 'A95': 0.0}\n",
        "\n",
        "        df['sex'] = df['personal_status'].replace(status_map)\n",
        "\n",
        "\n",
        "        # group credit history, savings, and employment\n",
        "        df['credit_history'] = df['credit_history'].apply(lambda x: group_credit_hist(x))\n",
        "        df['savings'] = df['savings'].apply(lambda x: group_savings(x))\n",
        "        df['employment'] = df['employment'].apply(lambda x: group_employ(x))\n",
        "        #df['age'] = df['age'].apply(lambda x: np.float(x >= 26))\n",
        "        df['status'] = df['status'].apply(lambda x: group_status(x))\n",
        "        df['personal_status'] = df['personal_status'].apply(lambda x: group_personal_status(x))\n",
        "        df['foreign_worker'] = df['foreign_worker'].apply(lambda x: group_foreign_worker(x))\n",
        "        group_foreign_worker\n",
        "        #print(df.isin(['NA']).sum(axis=0))\n",
        "\n",
        "        # print(df)\n",
        "        # uncomment if you want to save a version of the processed data\n",
        "        #df.to_csv(\"german_credit_data_processed.csv\")\n",
        "        return df\n",
        "\n",
        "    # Feature partitions\n",
        "    XD_features = ['number_of_credits', 'telephone',\n",
        "                     'foreign_worker', 'people_liable_for', 'skill_level', 'credit_history', 'installment_plans', 'residence_since', 'property', 'other_debtors', 'purpose', 'savings', 'employment', 'sex', 'age', 'personal_status', 'month']\n",
        "    D_features = ['sex', 'age']\n",
        "    Y_features = ['credit']\n",
        "    X_features = list(set(XD_features)-set(D_features))\n",
        "    categorical_features = ['installment_plans', 'telephone',\n",
        "                     'foreign_worker', 'skill_level', 'credit_history', 'property',\n",
        "                            'other_debtors', 'purpose', 'savings', 'employment', 'personal_status']\n",
        "\n",
        "    # privileged classes\n",
        "    all_privileged_classes = {\"sex\": [1.0],\n",
        "                              \"age\": lambda x: x > 25}\n",
        "\n",
        "    # protected attribute maps\n",
        "    all_protected_attribute_maps = {\"sex\": {1.0: 'Male', 0.0: 'Female'},\n",
        "                                    \"age\": {1.0: 'Old', 0.0: 'Young'}}\n",
        "\n",
        "    return GermanDataset(\n",
        "        label_name=Y_features[0],\n",
        "        favorable_classes=[1],\n",
        "        protected_attribute_names=D_features,\n",
        "        privileged_classes=[all_privileged_classes[x] for x in D_features],\n",
        "        instance_weights_name=None,\n",
        "        categorical_features=categorical_features,\n",
        "        features_to_keep=X_features+Y_features+D_features,\n",
        "        features_to_drop=[],\n",
        "        metadata={ 'label_maps': [{1.0: 'Good Credit', 2.0: 'Bad Credit'}],\n",
        "                   'protected_attribute_maps': [all_protected_attribute_maps[x]\n",
        "                                for x in D_features]},\n",
        "        custom_preprocessing=custom_preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHjx1gHqIU0x"
      },
      "source": [
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuETGJnvIU0x"
      },
      "source": [
        "### Step 2: Explore and familiarize with the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a72qzba_IU0x"
      },
      "source": [
        "<b>Q1: Analyse the dataset and answer the following:</b>\n",
        "- What is the number of records?\n",
        "- What is the number of attributes present with the preprocessing we provided?\n",
        "- What is the list of attribute names?\n",
        "- Are there missing values that could create biases?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZcHsBxZIU0y"
      },
      "outputs": [],
      "source": [
        "# Instanciating the German credit dataset\n",
        "dataset_gcredit = preproc_and_load_data_german()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-QweV_hIU0y"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Tip:</b> The documentation of \"AIF360 - German credit data\" dataset  can be found <a href=\"https://aif360.readthedocs.io/en/latest/modules/generated/aif360.datasets.GermanDataset.html\">[HERE]</a>. </div>\n",
        "\n",
        "\n",
        "Take a look at documentation of AIF360 and use existing methods to explore the dataset instance how to access the features with:<br> `dataset_gcredit.features`.\n",
        "\n",
        "You are also free to transform the dataset into a pandas dataframe to extract the needed information.\n",
        "Use <br>\n",
        "    `pd_gdata = pd.DataFrame(dataset_gcredit.features, columns=dataset_gcredit.feature_names)` <br>\n",
        "    to create the pandas dataframe\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnL3_NqTIU0y"
      },
      "source": [
        "-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOTIV9caIU0y"
      },
      "outputs": [],
      "source": [
        "### Some possible explorations ###\n",
        "# Number of records:\n",
        "\n",
        "# Number of features:\n",
        "\n",
        "# Feature names:\n",
        "\n",
        "# Number of missing values for each attribute ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIyR0iTSsyI0"
      },
      "source": [
        "### Stap 3: Visualization Tools (Optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cz-rJPI4zK0"
      },
      "source": [
        "Last quarter one of my students introduced me to a nice data exploring tool for pandas data frames. It is called <a href=\"https://pypi.org/project/pandas-profiling/\">[Padnas Profiling]</a>. I thought I would share it with you and let you decide what to do with it.\n",
        "\n",
        "Remember what we said about off-the-shelf tools: When you use tools and techniques, think about their design and possible (harmful) implications.\n",
        "\n",
        "Have Fun!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eC0zAZIps78G"
      },
      "outputs": [],
      "source": [
        "# 1. Install\n",
        "# Install Pandas Profiling tool\n",
        "!pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w09Bba556Pwk"
      },
      "outputs": [],
      "source": [
        "# 2. Import\n",
        "from pandas_profiling import ProfileReport"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkExA4Ek6P3X"
      },
      "outputs": [],
      "source": [
        "# 3. Use\n",
        "#<name of your data frame>.profile_report()\n",
        "pd_gdata.profile_report()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAR80f9aIU0y"
      },
      "source": [
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wjER9PIIU0y"
      },
      "source": [
        "## Part II Protected attributes, proxies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BppBqRBti9k"
      },
      "source": [
        "### Step 1: Sensitive and Protected Attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ0KNLNyIU0y"
      },
      "source": [
        "<b>Q2: Identification of protected attributes</b>\n",
        "\n",
        "a) Study the dataset and its documentation and identify which attributes that might raise unfairness concerns and should be considered protected (according to the law). Explain, in your opinion, why are these attributes protected provide exaples of bias or unfaireness for each identified attribute."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD7Px03DIU0y"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Tip:</b>\n",
        "\n",
        "Take a look at the following documents<br>\n",
        "<a href=\"https://www.equalityhumanrights.com/en/equality-act/protected-characteristics\">(1)\n",
        "Protected characteristics | Equality and Human Rights Commission (UK, 2021)</a><br>\n",
        "<a href=\"https://rm.coe.int/discrimination-artificial-intelligence-and-algorithmic-decision-making/1680925d73\">(2) Discrimination, Artificial Intelligence, and Algorithmic Decision-Making (2018)</a><br>\n",
        "<a href=\"http://ec.europa.eu/social/BlobServlet?docId=1691&langId=en&usg=AOvVaw3vI30bO3jisairH2Z7-nSl\">(3) Age discrimination and European Law (2005)</a>.\n",
        "\n",
        "Note: For your project, you have to find legal frameworks relevant to your context. Happy to help you validate your choices of frameworks.  \n",
        "\n",
        "<div>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byYv9J9HIU0y"
      },
      "source": [
        "-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgsZ4jJNIU0z"
      },
      "source": [
        "b) Study the dataset and its documentation and identify any further sensitive but \"non-protect\" attributes that could cause unfairness. Explain your reasoning. Provide examples of bias or unfairness related to each attribute in your context.\n",
        "\n",
        "\n",
        "***Hint:*** Protected attributes are sensitive attributes protected by law. This changes from one country/region to another. Sensitive attributes are attributes that could cause historical bias and can be protected by law or not depending on these countries/regions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hv8Ld7dIU0z"
      },
      "source": [
        "-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdR7TjuZIU0z"
      },
      "source": [
        "### Step 2: Identify Proxies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyQV4CWdIU0z"
      },
      "source": [
        "<b>Q3:  Identification of \"spurious\" proxies </b>\n",
        "\n",
        "a) Find the proxies for the attribute \"sex\".\n",
        "\n",
        "b) Find proxies for one additional protected attribut you identified in Q2-a.\n",
        "\n",
        "c) In your opinion, why do we want to identify proxies for protected attributes in a dataset? How should you handle the proxies?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPwXsAYiIU0z"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b> Tip: </b>A proxy attribute <i>Ap</i>  is an attribute that has a similar distribution as another attribute <i>Ax</i>, so having access to the proxy attribute <i>Ap</i> provides a good knowledge of the other attribute <i>Ax</i>. For instance, in the US the zipcode is a powerful proxy for race and education, the zipcode combined with websites visited is an even more powerful proxy, names in certain languages are strong proxies for gender, etc.<br>\n",
        "\n",
        "The simplest way to identify proxy attributes for a protected attribute <i>Ax</i> is to compute the correlation of <i>Ax</i>  with each other attributes in the dataset. The higher the corrolation (absolute value of the corrolation) the higher the likelihood an attribute is a proxy of <i>Ax</i> <br>\n",
        "\n",
        "You can use the `corr()` function of the pandas library to compute the correlation between two attributes\n",
        "</div>\n",
        "\n",
        "\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-Vr8ZXP8I2E"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB5dyQMz0iy2"
      },
      "source": [
        "## Part III: Representation Disparities, Skew and Bias </H3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWvCO1mUvV6y"
      },
      "source": [
        "### Step 1: Representation Disparity --> Representation Bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrmBjYfQIU0z"
      },
      "source": [
        "<br>\n",
        "<b>Q4: Is your data representative of the population (all its categories)</b>\n",
        "\n",
        "The aim of this section is to ensure the data is representative of the population it describes. While paying particular attention to sensitive and protected attributes.\n",
        "\n",
        "Use any combination of data visualisations, Tables, Textual \"Statistics\" and Textual analysis to address these guiding questions.\n",
        "\n",
        "a) Is the dataset we are working with representative of the German population with regard to age? Add any needed code or analysis to briefly justify your answer<br>\n",
        "b) Is the dataset we are working with representative of the German population with regard to gender? Add any needed code or analysis to briefly justify your answer\n",
        "c) Look at the joint distribution of the attributes for sex and personal_status=divorced/separated/married. Does the dataset seem to be representative of the German population?<br>\n",
        "d) Similarly, look at the distribution of foreign workers. Does the dataset seem to be representative of the German population?<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcEkGsg5IU0z"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b> Tip: </b> You can find demographic information from Wikipedia <a href=https://en.wikipedia.org/wiki/Demographics_of_Germany>[Here]</a>\n",
        "    \n",
        "Go to section <b><i>Demographic statistics</i></b> take a closer look at the most racent  <b><i>Age structure</i></b> data (it should be from 2018). Use this data to build a distribution of german population across age, then across gender and compare it to the distributions from <b><i>the German credit data</i></b> we are working with.\n",
        "\n",
        "It is up to you how you want to justify your answer, however using visualizations will provide more points (i.e., plots and diagram)\n",
        "</div>\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYvNpGAjIU0z"
      },
      "outputs": [],
      "source": [
        "# write you code here\n",
        "#\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ecLni1PIU0z"
      },
      "source": [
        "-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vALYwdGa54a9"
      },
      "source": [
        "### Step 2: Outcome Skews --> Historical Bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KiN6t-HIU0z"
      },
      "source": [
        "<b>Q5: Outcome Skews </b>\n",
        "\n",
        "Is there a skew towards certain groups? Are these groups historically marginalised or at risk of discrimination?:<br>\n",
        "\n",
        "Use any combination of data visualisations, Tables, Textual \"Statistics\" and Textual analysis to address these guiding questions.\n",
        "\n",
        "a) Analyse the dataset, and report the numbers of males/females with bad/good credit. Do the same for \"old\" / \" young\" people in the dataset. Normalise these numbers respectively over the total number of males/females, \"old\"/\"young\" for a fair comparison. For that, you can consider having 50 individuals for each of these groups.\n",
        "\n",
        "b) Briefly describe your findings and explain the impacts (on fairness) of using this dataset as training data (if any)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-JA8YQXIU0z"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b> Tip: </b> We provide a function for Normalised count per attribut and lable you are free to use it or implement your own method\n",
        "    \n",
        "`getNormalizedCount(pd_train_data, protected_attribute, label)`\n",
        "</div>\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sa1TYykRIU0z"
      },
      "outputs": [],
      "source": [
        "# Normalised count per attribut and lable\n",
        "def getNormalizedCount(pd_train_data, protected_attribute, label):\n",
        "    unnormalized_count = pd_train_data[[protected_attribute, label]].value_counts()\n",
        "    counts = {}\n",
        "    for attribute_value in pd_train_data[[protected_attribute]].value_counts().keys():\n",
        "        counts[attribute_value[0]] = pd_train_data[[protected_attribute]].value_counts()[attribute_value]\n",
        "    normalized_count = unnormalized_count[:]\n",
        "    for attribute_value, credit_value in pd_train_data[[protected_attribute, label]].value_counts().keys():\n",
        "        normalized_count[attribute_value, credit_value] = normalized_count[attribute_value, credit_value] * (50 / counts[attribute_value])\n",
        "    return normalized_count\n",
        "\n",
        "# add the credit labels to the data set.\n",
        "pd_gdata[\"credit\"] = dataset_gcredit.labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEBa9CquIU00"
      },
      "outputs": [],
      "source": [
        "### YOUR ANSWER HERE ###\n",
        "# ADD code here to print the AGE-CREDIT distribution\n",
        "\n",
        "\n",
        "# ADD code here to print the SEX-CREDIT distribution\n",
        "\n",
        "\n",
        "# ADD code here to visualise the results for both you can use stacked bar plots from pandas toolkit\n",
        "#<your dataframe>.size().unstack().plot(kind='bar', stacked=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w6LFn_TIU00"
      },
      "source": [
        "-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54WeKpG7IU00"
      },
      "source": [
        "## Part IV. Discuss Measurement Bias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dDQYPp9xcW8"
      },
      "source": [
        "Measurement Biases occur when choosing, collecting, or computing inadequate features and labels to use in a prediction problem. Features and labels are the concrete measurements chosen to approximate some construct (an idea or concept) that is not directly encoded or observable.\n",
        "</br></br>\n",
        "\n",
        "<b>Q6: Reflect on your featuers and lables</b> </br>\n",
        "There is no \"simple\" answer to this question, nor a \"technical\" quick fix. Your reflection and analysis should be contextual and responsible. Use outputs from Lecture 1 and the Responsible Data Guiding Principles from (D’Ignazio & Klein, 2016) to carry out your analysis and identify measurement bias in your data project. In the following, we provide a set of guiding questions that could help you articulate your thoughts and discussion for this type of bias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyOhMfqp0p1M"
      },
      "source": [
        "***Sample of Guiding questions:***\n",
        "\n",
        "a) Are you using inclusive non-harmful featuers and lables?\n",
        "\n",
        "b) Is your dataset making any harmful or discriminatory abstractions.\n",
        "\n",
        "c) Are you using the correct \"proxy\"/\"lable\" to predict the correct \"concept\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgIv3sU10Cjp"
      },
      "source": [
        "***Important Note***\n",
        "The german data set is a processed and simplified dataset. It is not obvious what assumptions were made to clean and label the dataset there, for it is hard to identify Measurement Biases in this dataset. It does not mean it is bias-free. On the contrary, this should warn you about using pre-processed, pre-packaged datasets. They are loaded with biases you can not identify and asses\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrEfASxr08pR"
      },
      "source": [
        "## End of the Lab, Well Done!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "RdR7TjuZIU0z"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}